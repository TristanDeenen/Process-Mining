{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBL Process Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Class definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Utils.LogFile import LogFile \n",
    "import tensorflow as tf\n",
    "import multiprocessing as mp\n",
    "import copy\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two different methods: \n",
    "- One csv file, which still has to be split into training and test data\n",
    "- Two csv files, which are already split into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attribute columns here\n",
    "case_attr = \"Case ID\"\n",
    "act_attr = \"concept:name\"\n",
    "time_attr = \"Complete Timestamp\"\n",
    "path = \"data/BPI_Challenge_2012_end.csv\"\n",
    "time_format = '%Y-%m-%d %H:%M:%S.%f'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logfile = LogFile(path, \",\", 0, None, time_attr=time_attr, trace_attr=case_attr,\n",
    "                   activity_attr=act_attr, time_format=time_format, convert=False, k=50)\n",
    "#logfile = logfile.create_subset(40)\n",
    "#logfile.add_end_events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_log = logfile.create_split_df()\n",
    "split_train, split_test = split_log.split_train_test(range(67, 73), type='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = split_train.data['Complete Timestamp'].max()\n",
    "split_case = split_train.data['Case ID'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(20, 22))\n",
    "\n",
    "sns.scatterplot(data=split_log.data, x=split_log.time, y=split_log.trace, hue=split_log.activity, ax=ax[0])\n",
    "sns.scatterplot(data=split_train.data, x=split_log.time, y=split_log.trace, ax=ax[1])\n",
    "sns.scatterplot(data=split_test.data, x=split_log.time, y=split_log.trace, ax=ax[1])\n",
    "\n",
    "fig.suptitle('Visualization of train-test split', size=25, weight='bold', y=1.01)\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[0].set_xlabel('')\n",
    "ax[0].set_ylabel('Case ID')\n",
    "ax[1].set_xlabel('Date')\n",
    "ax[1].set_ylabel('Case ID')\n",
    "\n",
    "ax[0].axvline(x=split_date, color = '#404040', linestyle='--', linewidth=2)\n",
    "ax[0].axhline(y=split_case, color = '#404040', linestyle='--', linewidth=2)\n",
    "ax[1].axvline(x=split_date, color = '#404040', linestyle='--', linewidth=2)\n",
    "ax[1].axhline(y=split_case, color = '#404040', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create k-context: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20204502\\OneDrive - TU Eindhoven\\Documents\\GitHub\\Process-Mining\\Process-Mining\\Utils\\LogFile.py:395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[self.time] = pd.to_datetime(data[self.time])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data lost due to overlap: 0.0832651595267075/n Best Split: 71\n"
     ]
    }
   ],
   "source": [
    "logfile.keep_attributes([logfile.trace, logfile.time, logfile.activity])\n",
    "activity_map = logfile.int_convert()\n",
    "logfile.add_start_date()\n",
    "logfile.create_k_context()\n",
    "log_train, log_test = logfile.split_train_test(range(67, 73), type='normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(dataset):\n",
    "    \"\"\"Adds a new column to a dataset with the converted timestamp to datetime\"\"\"\n",
    "\n",
    "    date_list = []\n",
    "\n",
    "    for time in dataset[logfile.time]:\n",
    "        date = datetime.strptime(time, logfile.time_format)\n",
    "        date_list.append(date)\n",
    "\n",
    "    dataset['time and date'] = date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add actual next event and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_actual_next(df_case):\n",
    "    \"\"\"Adds the actual next activity and time to next event to the final dataframe\"\"\"\n",
    "\n",
    "    # Create a list for all the actual next events for an case\n",
    "    event_lst = [event for event in df_case[logfile.activity]] # Gets a list of all events for a specific trace\n",
    "    event_lst = event_lst[1:] # Erase the first activity from the list (thus the second activity becomes first in the list)\n",
    "    event_lst.append('-') # Append a '-' to the end of the list (the last activity does not have a next activity)\n",
    "    \n",
    "    # Create a list for time of the next event\n",
    "    nexttime_lst1 = [time for time in df_case['time and date']]\n",
    "    nexttime_lst = nexttime_lst1[1:]\n",
    "    nexttime_lst.append(nexttime_lst[-1])\n",
    "\n",
    "    # Create the time difference list\n",
    "    time_diff = []\n",
    "    for i in range(len(nexttime_lst)):\n",
    "        time_diff.append((nexttime_lst[i] - nexttime_lst1[i]).total_seconds())\n",
    "\n",
    "    # Append columns to the case dataframe\n",
    "    df_case['Next event'] = event_lst\n",
    "    df_case['Time to next event'] = time_diff\n",
    "\n",
    "    trace_len = len(df_case)\n",
    "\n",
    "    return trace_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted next event and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_time(df_case, count_dict, time_dict):\n",
    "    for index, row in df_case.iterrows():\n",
    "        \n",
    "        # Get the amount of times an action occured in a certain position {action : {position_1 : count_1, position_2: count_2}}\n",
    "        if row[logfile.activity] in count_dict:\n",
    "            if index in count_dict[row[logfile.activity]]:\n",
    "                count_dict[row[logfile.activity]][index] += 1\n",
    "            else:\n",
    "                count_dict[row[logfile.activity]].update({index: 1})\n",
    "        else:\n",
    "            count_dict[row[logfile.activity]] = {index: 1}\n",
    "        \n",
    "        # Summation of the times to next action per position (index) {position: {\"sum\": summation_of_time, \"count\": amount_of_times_occured (to calculate mean)}}\n",
    "        if index in time_dict:\n",
    "            time_dict[index]['sum'] += row['Time to next event']\n",
    "            time_dict[index]['count'] += 1\n",
    "        else:\n",
    "            time_dict[index] = {'sum': row['Time to next event'], 'count': 1}\n",
    "\n",
    "def get_position_rank(max_trace_len, count_dict):\n",
    "    pos_rank_dict = {}\n",
    "    for i in range(max_trace_len):\n",
    "        init = 0\n",
    "        task = 0\n",
    "        for key in count_dict.keys():\n",
    "            try:\n",
    "                new = count_dict[key][i]\n",
    "            except:\n",
    "                new = 0\n",
    "            if new > init:\n",
    "                init = new\n",
    "                task = key\n",
    "\n",
    "        pos_rank_dict.update({i: task})\n",
    "    \n",
    "    return pos_rank_dict\n",
    "\n",
    "def get_mean_time(total_time_dict):\n",
    "    mean_time_dict = {}\n",
    "    for position in total_time_dict.keys():\n",
    "        mean_time = total_time_dict[position]['sum'] / total_time_dict[position]['count']\n",
    "        mean_time_dict[position] = mean_time\n",
    "    \n",
    "    return mean_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_pred(df_case, pos_rank_dict, mean_time_dict):\n",
    "    \n",
    "    # Prediction for the action\n",
    "    pred_act_lst = [pos_rank_dict[i] for i in range(len(df_case))]\n",
    "    pred_act_lst = pred_act_lst[1:]\n",
    "    pred_act_lst.append('-')\n",
    "\n",
    "    # Prediction for time\n",
    "    pred_time_lst = [mean_time_dict[i] for i in range(len(df_case))]\n",
    "\n",
    "    df_case['Event prediction'] = pred_act_lst \n",
    "    df_case['Time prediction'] = pred_time_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(dataframe, maximum=None):\n",
    "    \"\"\"Returns the training dataset with predictions and 2 dictionaries which predict next action and nexttime based on position\"\"\"\n",
    "    \n",
    "    dataset = dataframe\n",
    "    convert_time(dataset)\n",
    "\n",
    "    df_actual = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # Creating a dataframe with the actual events\n",
    "\n",
    "    cases = list(dataset[logfile.trace].unique())  \n",
    "    max_trace_len = 0  \n",
    "    pos_count_dict = {}\n",
    "    time_dict = {}\n",
    "    for case in cases[:maximum]:\n",
    "        df_case = dataset[dataset[logfile.trace] == case].copy().reset_index(drop=True)\n",
    "        trace_len = add_actual_next(df_case)\n",
    "        get_position_time(df_case, pos_count_dict, time_dict)\n",
    "        df_actual = pd.concat([df_actual, df_case])\n",
    "\n",
    "        if trace_len > max_trace_len:\n",
    "            max_trace_len = trace_len\n",
    "    \n",
    "\n",
    "\n",
    "    # Creating the predicitions\n",
    "    df_predicted = pd.DataFrame()\n",
    "    \n",
    "    pos_rank_dict = get_position_rank(max_trace_len, pos_count_dict)\n",
    "    mean_time_dict = get_mean_time(time_dict)\n",
    "\n",
    "    for case in cases[:maximum]:\n",
    "        df_case = df_actual[df_actual[logfile.trace] == case].copy().reset_index(drop=True)\n",
    "        create_event_pred(df_case, pos_rank_dict, mean_time_dict)\n",
    "        df_predicted = pd.concat([df_predicted,df_case])\n",
    "\n",
    "\n",
    "\n",
    "    return df_predicted, pos_rank_dict, mean_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline(dataframe, train_pos, train_time):\n",
    "    \"\"\"Creates the test dataset including the predictions based on the training dataset\"\"\"\n",
    "    \n",
    "    dataset = dataframe\n",
    "    convert_time(dataset)\n",
    "\n",
    "    df_predict = pd.DataFrame()\n",
    "    cases = list(dataset[logfile.trace].unique())  \n",
    "    for case in cases:\n",
    "        df_case = dataset[dataset[logfile.trace] == case].copy().reset_index(drop=True)\n",
    "        _ = add_actual_next(df_case)\n",
    "        create_event_pred(df_case, train_pos, train_time)\n",
    "        df_predict = pd.concat([df_predict, df_case])\n",
    "    \n",
    "    return df_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(dataset):\n",
    "    event_accuracy = np.mean(dataset['Next event'] ==  dataset['Event prediction'])\n",
    "    time_accuracy = np.mean(abs(dataset['Time to next event'] - dataset['Time prediction'])) / 86400  # Mean Absolute Error in days\n",
    "    \n",
    "    return event_accuracy, time_accuracy\n",
    "\n",
    "def get_sample_weight(dataset):\n",
    "    sample_dict = {}\n",
    "    for event in dataset[act_attr]:\n",
    "        if event in sample_dict:\n",
    "            sample_dict[event] += 1\n",
    "        else:\n",
    "            sample_dict[event] = 1\n",
    "\n",
    "\n",
    "def get_balanced_accuracy(actual_event, event_pred, actual_time, time_pred):\n",
    "    event_balanced_accuracy = balanced_accuracy_score(actual_event, event_pred, adjusted=True) #possibly use sample weight\n",
    "    time_accuracy = np.mean(abs(actual_time - time_pred)) / 86400  # Mean Absolute Error in days\n",
    "    return event_balanced_accuracy, time_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = log_train.data\n",
    "test_df = log_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20204502\\AppData\\Local\\Temp\\ipykernel_21512\\2085041681.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['time and date'] = date_list\n",
      "C:\\Users\\20204502\\AppData\\Local\\Temp\\ipykernel_21512\\2085041681.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['time and date'] = date_list\n"
     ]
    }
   ],
   "source": [
    "train_df, train_pos, train_time = train_baseline(train_df)\n",
    "test_df = test_baseline(test_df, train_pos, train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest event prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = log_train.contextdata.copy()\n",
    "df_X.loc[df_X['Complete Timestamp_Prev0'] == 0, \"Complete Timestamp_Prev0\"] = df_X['Start Date']\n",
    "df_X['Complete Timestamp_Prev0'] = pd.to_datetime(df_X['Complete Timestamp_Prev0'])\n",
    "df_X['Complete Timestamp'] = pd.to_datetime(df_X['Complete Timestamp'])\n",
    "df_X['Start Date'] = pd.to_datetime(df_X['Start Date'])\n",
    "df_X['time_since_start'] = (df_X['Complete Timestamp_Prev0'] - df_X['Start Date']).dt.total_seconds()\n",
    "df_X['day_previous_event'] = df_X['Complete Timestamp_Prev0'].dt.weekday\n",
    "df_X['hour_previous_event'] = df_X['Complete Timestamp_Prev0'].dt.hour\n",
    "df_X['time_to_next_event'] = (df_X['Complete Timestamp'] - df_X['Complete Timestamp_Prev0']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_test = log_test.contextdata.copy()\n",
    "df_X_test.loc[df_X_test['Complete Timestamp_Prev0'] == 0, \"Complete Timestamp_Prev0\"] = df_X_test['Start Date']\n",
    "df_X_test['Complete Timestamp_Prev0'] = pd.to_datetime(df_X_test['Complete Timestamp_Prev0'])\n",
    "df_X_test['Complete Timestamp'] = pd.to_datetime(df_X_test['Complete Timestamp'])\n",
    "df_X_test['Start Date'] = pd.to_datetime(df_X_test['Start Date'])\n",
    "df_X_test['time_since_start'] = (df_X_test['Complete Timestamp_Prev0'] - df_X_test['Start Date']).dt.total_seconds()\n",
    "df_X_test['day_previous_event'] = df_X_test['Complete Timestamp_Prev0'].dt.weekday\n",
    "df_X_test['hour_previous_event'] = df_X_test['Complete Timestamp_Prev0'].dt.hour\n",
    "df_X_test['time_to_next_event'] = (df_X_test['Complete Timestamp'] - df_X_test['Complete Timestamp_Prev0']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8387142598858383\n"
     ]
    }
   ],
   "source": [
    "y = df_X[logfile.activity]\n",
    "columns = ['time_since_start', 'day_previous_event', 'hour_previous_event']\n",
    "columns.extend([\"%s_Prev%i\" % (logfile.activity, i) for i in range(logfile.k)])\n",
    "X = df_X[columns]\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf = rf.fit(X, y)\n",
    "\n",
    "df_X['rf_prediction'] = rf.predict(df_X[columns])\n",
    "df_X_test['rf_prediction'] = rf.predict(df_X_test[columns])\n",
    "\n",
    "\n",
    "accuracy_event = np.mean(df_X_test['rf_prediction'] == df_X_test[logfile.activity])\n",
    "\n",
    "print(accuracy_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38749239118167006\n"
     ]
    }
   ],
   "source": [
    "y2 = df_X['time_to_next_event']\n",
    "columns = ['time_since_start', 'day_previous_event', 'hour_previous_event']\n",
    "columns.extend([\"%s_Prev%i\" % (logfile.activity, i) for i in range(logfile.k)])\n",
    "X2 = df_X[columns]\n",
    "\n",
    "\n",
    "rf2 = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "rf2 = rf2.fit(X2, y2)\n",
    "\n",
    "df_X['rf_time_prediction'] = rf2.predict(df_X[columns])\n",
    "df_X_test['rf_time_prediction'] = rf2.predict(df_X_test[columns])\n",
    "\n",
    "time_mae = np.mean(abs(df_X_test['time_to_next_event'] - df_X_test['rf_time_prediction'])) / 86400\n",
    "print(time_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_log(log):\n",
    "\n",
    "    activities = np.unique(log.data[log.activity])\n",
    "    X = np.zeros((len(log.contextdata), log.k, len(activities)+ 7), dtype=np.float32)\n",
    "    y_a = np.zeros((len(log.contextdata), len(activities) + 1), dtype=np.float32)\n",
    "    y_t = np.zeros((len(log.contextdata)), dtype=np.float32)\n",
    "    j = 0\n",
    "    time_diff = 0\n",
    "    for row in log.contextdata.iterrows():\n",
    "        \n",
    "            act = getattr(row[1], log.activity)\n",
    "            event_str = getattr(row[1], log.time)\n",
    "            prev_str = getattr(row[1], \"%s_Prev0\" % (log.time))\n",
    "            start_str = getattr(row[1], \"Start Date\")\n",
    "            event_time = time.strptime(event_str, logfile.time_format)\n",
    "            start_time = time.strptime(start_str, logfile.time_format)\n",
    "\n",
    "            if prev_str != 0:\n",
    "                prev_time = time.strptime(prev_str, logfile.time_format)\n",
    "                diff_prev_event = datetime.fromtimestamp(time.mktime(event_time)) \\\n",
    "                                          - datetime.fromtimestamp(time.mktime(prev_time))\n",
    "                diff = diff_prev_event.total_seconds()\n",
    "\n",
    "            else: \n",
    "                diff = 0\n",
    "\n",
    "                        \n",
    "    \n",
    "            y_a[j, act] = 1\n",
    "            y_t[j] = diff            \n",
    "\n",
    "            k = 0\n",
    "            \n",
    "            for i in range(log.k -1, -1, -1):\n",
    "                \n",
    "                if getattr(row[1], \"%s_Prev%i\" % (log.activity, i)) != 0: # 0 indicates no activity (first activity is encoded to 1)\n",
    "                    X[j, log.k - i - 1, getattr(row[1], \"%s_Prev%i\" % (log.activity, i))] = 1\n",
    "                X[j, log.k - i - 1, len(activities)+2] = k\n",
    "                #X[j, log.k - i - 1, len(activities) + 3] = time_diff # Diff in seconds\n",
    "\n",
    " \n",
    "                str_time = getattr(row[1], \"%s_Prev%i\" % (log.time, i))\n",
    "                if str_time != 0:\n",
    "                    event_time = time.strptime(str_time, logfile.time_format)\n",
    "                    time_since_start = datetime.fromtimestamp(time.mktime(event_time)) \\\n",
    "                                        - datetime.fromtimestamp(time.mktime(start_time))\n",
    "                    X[j, log.k - i - 1, len(activities) + 4] = event_time.tm_hour # Hour of day\n",
    "                    X[j, log.k - i - 1, len(activities) + 5] = event_time.tm_wday # Day of the week\n",
    "                    X[j, log.k - i - 1, len(activities) + 6] = time_since_start.total_seconds() # Seconds since start\n",
    "                else: \n",
    "                    X[j, log.k - i - 1, len(activities) + 4] = 0 \n",
    "                    X[j, log.k - i - 1, len(activities) + 5] = 0 \n",
    "                    X[j, log.k - i - 1, len(activities) + 6] = 0\n",
    "                    \n",
    "                prev_str = getattr(row[1], \"%s_Prev%i\" % (log.time, i + 1))\n",
    "                if prev_str != 0:\n",
    "                    \n",
    "                    prev_time = time.strptime(prev_str, logfile.time_format)\n",
    "                    diff_prev_event = datetime.fromtimestamp(time.mktime(event_time)) \\\n",
    "                                        - datetime.fromtimestamp(time.mktime(prev_time))\n",
    "                    time_diff = diff_prev_event.total_seconds() \n",
    "                    X[j, log.k - i - 1, len(activities) + 3] = time_diff\n",
    "                else:\n",
    "                     X[j, log.k - i - 1, len(activities) + 3] = 0\n",
    "\n",
    "                        \n",
    "\n",
    "                k += 1\n",
    "\n",
    "            j += 1\n",
    "\n",
    "    return X, y_a, y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSTM(log, epochs=4, early_stop=42):\n",
    "\n",
    "\n",
    "    print(\"Transforming log...\")\n",
    "    X, y_a, y_t = transform_log(log)\n",
    "\n",
    "    # build the model:\n",
    "    print('Build model...')\n",
    "    main_input = Input(shape=(log.k, len(np.unique(log.data[log.activity]))+7), name='main_input')\n",
    "    # train a 2-layer LSTM with one shared layer\n",
    "    l1 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(main_input) # the shared layer\n",
    "    b1 = BatchNormalization()(l1)\n",
    "    l2_1 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(b1) # the layer specialized in activity prediction\n",
    "    b2_1 = BatchNormalization()(l2_1)\n",
    "    l2_2 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(b1) # the layer specialized in time prediction\n",
    "    b2_2 = BatchNormalization()(l2_2)\n",
    "\n",
    "    act_output = Dense(len(np.unique(log.data[log.activity])) + 1, activation='softmax', kernel_initializer='glorot_uniform', name='act_output')(b2_1)\n",
    "    time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(b2_2)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[main_input], outputs=[act_output, time_output])\n",
    "\n",
    "    opt = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, clipvalue=3)\n",
    "\n",
    "    model.compile(loss={'act_output':'categorical_crossentropy', 'time_output': 'mae'}, optimizer=opt)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=early_stop)\n",
    "    model_checkpoint = ModelCheckpoint(os.path.join(\"model\", 'model_{epoch:03d}-{val_loss:.2f}.h5'), monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "    lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    if len(y_a) > 10:\n",
    "        split = 0.2\n",
    "    else:\n",
    "        split = 0\n",
    "\n",
    "    model.fit(X, {'act_output': y_a, 'time_output': y_t}, validation_split=split, verbose=2, callbacks=[early_stopping, lr_reducer], batch_size=log.k, epochs=epochs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, log):\n",
    "    X, y_a, y_t = transform_log(log)\n",
    "    pred_act, pred_time = model.predict(X)\n",
    "    predict_vals = np.argmax(pred_act, axis=1)\n",
    "    pred_time = pred_time.reshape(-1)\n",
    "    #predict_probs = predictions[np.arange(predictions.shape[0]), predict_vals]\n",
    "    expected_vals = np.argmax(y_a, axis=1)\n",
    "    #expected_probs = predictions[np.arange(predictions.shape[0]), expected_vals]\n",
    "    activity_acc = np.mean(expected_vals ==  predict_vals)\n",
    "    mae_time = np.mean(abs(y_t - pred_time)) / 86400\n",
    "    return predict_vals, pred_time, activity_acc, mae_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming log...\n",
      "Build model...\n",
      "Epoch 1/6\n",
      "2591/2591 - 94s - loss: 34465.8594 - act_output_loss: 1.4536 - time_output_loss: 34464.4375 - val_loss: 24634.1211 - val_act_output_loss: 1.3321 - val_time_output_loss: 24632.7754 - lr: 0.0020 - 94s/epoch - 36ms/step\n",
      "Epoch 2/6\n",
      "2591/2591 - 85s - loss: 34432.8008 - act_output_loss: 1.2684 - time_output_loss: 34431.5156 - val_loss: 24622.6797 - val_act_output_loss: 1.2917 - val_time_output_loss: 24621.3945 - lr: 0.0020 - 85s/epoch - 33ms/step\n",
      "Epoch 3/6\n",
      "2591/2591 - 94s - loss: 34414.9492 - act_output_loss: 1.2218 - time_output_loss: 34413.6641 - val_loss: 24621.8867 - val_act_output_loss: 1.2157 - val_time_output_loss: 24620.6582 - lr: 0.0020 - 94s/epoch - 36ms/step\n",
      "Epoch 4/6\n",
      "2591/2591 - 100s - loss: 34404.8477 - act_output_loss: 1.1962 - time_output_loss: 34403.7383 - val_loss: 24617.0762 - val_act_output_loss: 1.3138 - val_time_output_loss: 24615.7441 - lr: 0.0020 - 100s/epoch - 38ms/step\n",
      "Epoch 5/6\n",
      "2591/2591 - 103s - loss: 34379.6797 - act_output_loss: 1.1734 - time_output_loss: 34378.5547 - val_loss: 24734.6035 - val_act_output_loss: 1.2646 - val_time_output_loss: 24733.3438 - lr: 0.0020 - 103s/epoch - 40ms/step\n",
      "Epoch 6/6\n",
      "2591/2591 - 111s - loss: 34360.0039 - act_output_loss: 1.1321 - time_output_loss: 34358.8359 - val_loss: 24627.0605 - val_act_output_loss: 1.1704 - val_time_output_loss: 24625.8984 - lr: 0.0020 - 111s/epoch - 43ms/step\n"
     ]
    }
   ],
   "source": [
    "model = train_LSTM(log_train, epochs=6, early_stop=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_act, pred_time, acc_act, mae_time = test(model, log_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset Compiling and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Complete Timestamp</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>time and date</th>\n",
       "      <th>Next event</th>\n",
       "      <th>Time to next event</th>\n",
       "      <th>Event prediction</th>\n",
       "      <th>Time prediction</th>\n",
       "      <th>LSTM event prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.354</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:24:45.084</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:24:45.084</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>9.690</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>35.273265</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:24:54.774</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:24:54.774</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>1237.301</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>7242.202085</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:45:32.075</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:45:32.075</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>98.595</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>7792.050159</td>\n",
       "      <td>A_DECLINED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:47:10.670</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:47:10.670</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>3.162</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>1165.050331</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case ID       Complete Timestamp        concept:name  \\\n",
       "0   202653  2012-01-20 17:24:44.730         A_SUBMITTED   \n",
       "1   202653  2012-01-20 17:24:45.084   A_PARTLYSUBMITTED   \n",
       "2   202653  2012-01-20 17:24:54.774  W_Afhandelen leads   \n",
       "3   202653  2012-01-20 17:45:32.075  W_Afhandelen leads   \n",
       "4   202653  2012-01-20 17:47:10.670          A_DECLINED   \n",
       "\n",
       "                Start Date           time and date          Next event  \\\n",
       "0  2012-01-20 17:24:44.730 2012-01-20 17:24:44.730   A_PARTLYSUBMITTED   \n",
       "1  2012-01-20 17:24:44.730 2012-01-20 17:24:45.084  W_Afhandelen leads   \n",
       "2  2012-01-20 17:24:44.730 2012-01-20 17:24:54.774  W_Afhandelen leads   \n",
       "3  2012-01-20 17:24:44.730 2012-01-20 17:45:32.075          A_DECLINED   \n",
       "4  2012-01-20 17:24:44.730 2012-01-20 17:47:10.670  W_Afhandelen leads   \n",
       "\n",
       "   Time to next event        Event prediction  Time prediction  \\\n",
       "0               0.354       A_PARTLYSUBMITTED         0.567291   \n",
       "1               9.690      W_Afhandelen leads        35.273265   \n",
       "2            1237.301      W_Afhandelen leads      7242.202085   \n",
       "3              98.595  W_Completeren aanvraag      7792.050159   \n",
       "4               3.162  W_Completeren aanvraag      1165.050331   \n",
       "\n",
       "    LSTM event prediction  \n",
       "0       A_PARTLYSUBMITTED  \n",
       "1      W_Afhandelen leads  \n",
       "2      W_Afhandelen leads  \n",
       "3              A_DECLINED  \n",
       "4  W_Completeren aanvraag  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Next event'].replace(activity_map, inplace=True)\n",
    "test_df['Event prediction'].replace(activity_map, inplace=True)\n",
    "test_df[log_test.activity].replace(activity_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_act = [activity_map[act] for act in pred_act]\n",
    "LSTM_act = LSTM_act[1:]\n",
    "LSTM_act.append('-')\n",
    "test_df['LSTM event prediction'] = LSTM_act\n",
    "test_df.loc[test_df[log_test.activity] == \"End\", \"LSTM event prediction\"] = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_time = list(pred_time[1:])\n",
    "LSTM_time.append('-')\n",
    "test_df['LSTM time prediction'] = LSTM_time\n",
    "test_df.loc[test_df[log_test.activity] == 'End', 'LSTM time prediction'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_act = [activity_map[act] for act in df_X_test['rf_prediction']]\n",
    "rf_act = rf_act[1:]\n",
    "rf_act.append('-')\n",
    "test_df['RF event prediction'] = rf_act\n",
    "test_df.loc[test_df[log_test.activity] == \"End\", \"RF event prediction\"] = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_time = list(df_X_test['rf_time_prediction'][1:])\n",
    "rf_time.append('-')\n",
    "test_df['RF time prediction'] = rf_time\n",
    "test_df.loc[test_df[log_test.activity] == 'End', 'RF time prediction'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df[log_test.activity] != 'End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Complete Timestamp</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>time and date</th>\n",
       "      <th>Next event</th>\n",
       "      <th>Time to next event</th>\n",
       "      <th>Event prediction</th>\n",
       "      <th>Time prediction</th>\n",
       "      <th>LSTM event prediction</th>\n",
       "      <th>LSTM time prediction</th>\n",
       "      <th>RF event prediction</th>\n",
       "      <th>RF time prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.354</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>98.187439</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.356812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:24:45.084</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:24:45.084</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>9.690</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>35.273265</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>24.644608</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>28.1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:24:54.774</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:24:54.774</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>1237.301</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>7242.202085</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>9562.004883</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2651.11963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:45:32.075</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:45:32.075</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>98.595</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>7792.050159</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>256.912781</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2393.26746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:47:10.670</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:47:10.670</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>3.162</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>1165.050331</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>477.817291</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>46694.18548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case ID       Complete Timestamp        concept:name  \\\n",
       "0   202653  2012-01-20 17:24:44.730         A_SUBMITTED   \n",
       "1   202653  2012-01-20 17:24:45.084   A_PARTLYSUBMITTED   \n",
       "2   202653  2012-01-20 17:24:54.774  W_Afhandelen leads   \n",
       "3   202653  2012-01-20 17:45:32.075  W_Afhandelen leads   \n",
       "4   202653  2012-01-20 17:47:10.670          A_DECLINED   \n",
       "\n",
       "                Start Date           time and date          Next event  \\\n",
       "0  2012-01-20 17:24:44.730 2012-01-20 17:24:44.730   A_PARTLYSUBMITTED   \n",
       "1  2012-01-20 17:24:44.730 2012-01-20 17:24:45.084  W_Afhandelen leads   \n",
       "2  2012-01-20 17:24:44.730 2012-01-20 17:24:54.774  W_Afhandelen leads   \n",
       "3  2012-01-20 17:24:44.730 2012-01-20 17:45:32.075          A_DECLINED   \n",
       "4  2012-01-20 17:24:44.730 2012-01-20 17:47:10.670  W_Afhandelen leads   \n",
       "\n",
       "   Time to next event        Event prediction  Time prediction  \\\n",
       "0               0.354       A_PARTLYSUBMITTED         0.567291   \n",
       "1               9.690      W_Afhandelen leads        35.273265   \n",
       "2            1237.301      W_Afhandelen leads      7242.202085   \n",
       "3              98.595  W_Completeren aanvraag      7792.050159   \n",
       "4               3.162  W_Completeren aanvraag      1165.050331   \n",
       "\n",
       "    LSTM event prediction LSTM time prediction RF event prediction  \\\n",
       "0       A_PARTLYSUBMITTED            98.187439   A_PARTLYSUBMITTED   \n",
       "1      W_Afhandelen leads            24.644608          A_DECLINED   \n",
       "2      W_Afhandelen leads          9562.004883  W_Afhandelen leads   \n",
       "3              A_DECLINED           256.912781       A_PREACCEPTED   \n",
       "4  W_Completeren aanvraag           477.817291  W_Afhandelen leads   \n",
       "\n",
       "  RF time prediction  \n",
       "0           0.356812  \n",
       "1            28.1235  \n",
       "2         2651.11963  \n",
       "3         2393.26746  \n",
       "4        46694.18548  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_event_acc, base_time_mae = get_balanced_accuracy(test_df['Next event'], test_df['Event prediction'], test_df['Time to next event'], test_df['Time prediction'])\n",
    "LSTM_event_acc, LSTM_time_mae = get_balanced_accuracy(test_df['Next event'], test_df['LSTM event prediction'], test_df['Time to next event'], test_df['LSTM time prediction'])\n",
    "RF_event_acc, RF_time_mae = get_balanced_accuracy(test_df['Next event'], test_df['RF event prediction'], test_df['Time to next event'], test_df['RF time prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Complete Timestamp</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>time and date</th>\n",
       "      <th>Next event</th>\n",
       "      <th>Time to next event</th>\n",
       "      <th>Event prediction</th>\n",
       "      <th>Time prediction</th>\n",
       "      <th>LSTM event prediction</th>\n",
       "      <th>LSTM time prediction</th>\n",
       "      <th>RF event prediction</th>\n",
       "      <th>RF time prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202653</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>2012-01-20 17:24:44.730</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.354</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>98.187439</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.356812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202656</td>\n",
       "      <td>2012-01-20 17:34:09.591</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-01-20 17:34:09.591</td>\n",
       "      <td>2012-01-20 17:34:09.591</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.198</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>98.187439</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.356812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202659</td>\n",
       "      <td>2012-01-20 17:35:39.051</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-01-20 17:35:39.051</td>\n",
       "      <td>2012-01-20 17:35:39.051</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.279</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>98.187439</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.356812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202662</td>\n",
       "      <td>2012-01-20 17:38:44.874</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-01-20 17:38:44.874</td>\n",
       "      <td>2012-01-20 17:38:44.874</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.237</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>98.187439</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.356812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202665</td>\n",
       "      <td>2012-01-20 17:46:59.963</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-01-20 17:46:59.963</td>\n",
       "      <td>2012-01-20 17:46:59.963</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.285</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>98.187439</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.356812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214364</td>\n",
       "      <td>2012-02-29 23:22:24.570</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-02-29 23:22:24.570</td>\n",
       "      <td>2012-02-29 23:22:24.570</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.087</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>91.826683</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.829388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214367</td>\n",
       "      <td>2012-02-29 23:28:41.098</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-02-29 23:28:41.098</td>\n",
       "      <td>2012-02-29 23:28:41.098</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.100</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>91.826683</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.829388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214370</td>\n",
       "      <td>2012-02-29 23:28:55.349</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-02-29 23:28:55.349</td>\n",
       "      <td>2012-02-29 23:28:55.349</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.130</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>91.826683</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.829388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214373</td>\n",
       "      <td>2012-02-29 23:43:09.766</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-02-29 23:43:09.766</td>\n",
       "      <td>2012-02-29 23:43:09.766</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.133</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>91.826683</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.829388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214376</td>\n",
       "      <td>2012-02-29 23:51:16.799</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-02-29 23:51:16.799</td>\n",
       "      <td>2012-02-29 23:51:16.799</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.624</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.567291</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>91.826683</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.829388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3796 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case ID       Complete Timestamp concept:name               Start Date  \\\n",
       "0    202653  2012-01-20 17:24:44.730  A_SUBMITTED  2012-01-20 17:24:44.730   \n",
       "0    202656  2012-01-20 17:34:09.591  A_SUBMITTED  2012-01-20 17:34:09.591   \n",
       "0    202659  2012-01-20 17:35:39.051  A_SUBMITTED  2012-01-20 17:35:39.051   \n",
       "0    202662  2012-01-20 17:38:44.874  A_SUBMITTED  2012-01-20 17:38:44.874   \n",
       "0    202665  2012-01-20 17:46:59.963  A_SUBMITTED  2012-01-20 17:46:59.963   \n",
       "..      ...                      ...          ...                      ...   \n",
       "0    214364  2012-02-29 23:22:24.570  A_SUBMITTED  2012-02-29 23:22:24.570   \n",
       "0    214367  2012-02-29 23:28:41.098  A_SUBMITTED  2012-02-29 23:28:41.098   \n",
       "0    214370  2012-02-29 23:28:55.349  A_SUBMITTED  2012-02-29 23:28:55.349   \n",
       "0    214373  2012-02-29 23:43:09.766  A_SUBMITTED  2012-02-29 23:43:09.766   \n",
       "0    214376  2012-02-29 23:51:16.799  A_SUBMITTED  2012-02-29 23:51:16.799   \n",
       "\n",
       "             time and date         Next event  Time to next event  \\\n",
       "0  2012-01-20 17:24:44.730  A_PARTLYSUBMITTED               0.354   \n",
       "0  2012-01-20 17:34:09.591  A_PARTLYSUBMITTED               0.198   \n",
       "0  2012-01-20 17:35:39.051  A_PARTLYSUBMITTED               0.279   \n",
       "0  2012-01-20 17:38:44.874  A_PARTLYSUBMITTED               0.237   \n",
       "0  2012-01-20 17:46:59.963  A_PARTLYSUBMITTED               0.285   \n",
       "..                     ...                ...                 ...   \n",
       "0  2012-02-29 23:22:24.570  A_PARTLYSUBMITTED               0.087   \n",
       "0  2012-02-29 23:28:41.098  A_PARTLYSUBMITTED               0.100   \n",
       "0  2012-02-29 23:28:55.349  A_PARTLYSUBMITTED               0.130   \n",
       "0  2012-02-29 23:43:09.766  A_PARTLYSUBMITTED               0.133   \n",
       "0  2012-02-29 23:51:16.799  A_PARTLYSUBMITTED               0.624   \n",
       "\n",
       "     Event prediction  Time prediction LSTM event prediction  \\\n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "..                ...              ...                   ...   \n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "0   A_PARTLYSUBMITTED         0.567291     A_PARTLYSUBMITTED   \n",
       "\n",
       "   LSTM time prediction RF event prediction RF time prediction  \n",
       "0             98.187439   A_PARTLYSUBMITTED           0.356812  \n",
       "0             98.187439   A_PARTLYSUBMITTED           0.356812  \n",
       "0             98.187439   A_PARTLYSUBMITTED           0.356812  \n",
       "0             98.187439   A_PARTLYSUBMITTED           0.356812  \n",
       "0             98.187439   A_PARTLYSUBMITTED           0.356812  \n",
       "..                  ...                 ...                ...  \n",
       "0             91.826683   A_PARTLYSUBMITTED           0.829388  \n",
       "0             91.826683   A_PARTLYSUBMITTED           0.829388  \n",
       "0             91.826683   A_PARTLYSUBMITTED           0.829388  \n",
       "0             91.826683   A_PARTLYSUBMITTED           0.829388  \n",
       "0             91.826683   A_PARTLYSUBMITTED           0.829388  \n",
       "\n",
       "[3796 rows x 13 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df[log_test.activity] == 'A_SUBMITTED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23758 13308\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df.loc[test_df['LSTM event prediction'] == \"W_Nabellen offertes\"]), len(test_df.loc[test_df['Next event'] == \"W_Nabellen offertes\"]))\n",
    "\n",
    "# LSTM predicitons of \"W_Nabellen offertes\" = 23758 \n",
    "# Next events of \"W_Nabellen offertes\" = 13308\n",
    "# Due to the LSTM continously predicting a long sequence of \"W_Nabellen offertes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM event prediction\n",
       "A_FINALIZED                        136\n",
       "End                                 89\n",
       "O_CREATED                            8\n",
       "O_SENT                             105\n",
       "W_Afhandelen leads                 458\n",
       "W_Completeren aanvraag            1496\n",
       "W_Nabellen incomplete dossiers     575\n",
       "W_Nabellen offertes                713\n",
       "W_Valideren aanvraag               216\n",
       "Name: Case ID, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['Next event'] == \"End\"].groupby('LSTM event prediction')['Case ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263 3796\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df.loc[test_df['LSTM event prediction'] == \"End\"]), len(test_df.loc[test_df['Next event'] == \"End\"]))\n",
    "# Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM event prediction\n",
       "A_FINALIZED                        136\n",
       "End                                 89\n",
       "O_CREATED                            8\n",
       "O_SENT                             105\n",
       "W_Afhandelen leads                 458\n",
       "W_Completeren aanvraag            1496\n",
       "W_Nabellen incomplete dossiers     575\n",
       "W_Nabellen offertes                713\n",
       "W_Valideren aanvraag               216\n",
       "Name: Case ID, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['Next event'] == \"End\"].groupby('LSTM event prediction')['Case ID'].count() # What does the LSTM predict when the next event = \"End\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21794 16685\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df.loc[test_df['LSTM event prediction'] == \"W_Completeren aanvraag\"]), len(test_df.loc[test_df['Next event'] == \"W_Completeren aanvraag\"]))\n",
    "# Conclusion! LSTM very bad at predicting when trace contains a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_PARTLYSUBMITTED: 100.0%\n",
      "W_Afhandelen leads: 69.89999999999999%\n",
      "A_DECLINED: 18.099999999999998%\n",
      "End: 2.3%\n",
      "A_PREACCEPTED: 12.5%\n",
      "W_Completeren aanvraag: 86.3%\n",
      "A_ACCEPTED: 10.7%\n",
      "O_SELECTED: 6.9%\n",
      "A_FINALIZED: 26.8%\n",
      "O_CREATED: 28.7%\n",
      "O_SENT: 52.2%\n",
      "W_Nabellen offertes: 90.7%\n",
      "O_CANCELLED: 0.0%\n",
      "A_CANCELLED: 0.0%\n",
      "O_SENT_BACK: 0.0%\n",
      "W_Valideren aanvraag: 11.1%\n",
      "O_DECLINED: 0.0%\n",
      "W_Nabellen incomplete dossiers: 65.7%\n",
      "O_ACCEPTED: 0.0%\n",
      "A_APPROVED: 0.0%\n",
      "A_REGISTERED: 0.0%\n",
      "A_ACTIVATED: 0.0%\n",
      "W_Beoordelen fraude: 0.5%\n",
      "W_Wijzigen contractgegevens: 0.0%\n"
     ]
    }
   ],
   "source": [
    "for pred in test_df['Next event'].unique():\n",
    "    df_pred = test_df.loc[test_df['Next event'] == pred] \n",
    "    LSTM_acc = round(np.mean(df_pred['Next event'] == df_pred['LSTM event prediction']),3) * 100\n",
    "    print(\"%s: %s%%\" % (pred, LSTM_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_PARTLYSUBMITTED: 100.0%\n",
      "W_Afhandelen leads: 75.8%\n",
      "A_DECLINED: 30.4%\n",
      "End: 89.60000000000001%\n",
      "A_PREACCEPTED: 35.199999999999996%\n",
      "W_Completeren aanvraag: 94.1%\n",
      "A_ACCEPTED: 29.299999999999997%\n",
      "O_SELECTED: 65.0%\n",
      "A_FINALIZED: 72.39999999999999%\n",
      "O_CREATED: 100.0%\n",
      "O_SENT: 100.0%\n",
      "W_Nabellen offertes: 97.0%\n",
      "O_CANCELLED: 45.300000000000004%\n",
      "A_CANCELLED: 31.6%\n",
      "O_SENT_BACK: 45.6%\n",
      "W_Valideren aanvraag: 86.7%\n",
      "O_DECLINED: 16.5%\n",
      "W_Nabellen incomplete dossiers: 92.30000000000001%\n",
      "O_ACCEPTED: 22.2%\n",
      "A_APPROVED: 28.999999999999996%\n",
      "A_REGISTERED: 50.3%\n",
      "A_ACTIVATED: 56.2%\n",
      "W_Beoordelen fraude: 71.1%\n",
      "W_Wijzigen contractgegevens: 0.0%\n"
     ]
    }
   ],
   "source": [
    "for pred in test_df['Next event'].unique():\n",
    "    df_pred = test_df.loc[test_df['Next event'] == pred] \n",
    "    RF_acc = round(np.mean(df_pred['Next event'] == df_pred['RF event prediction']), 3) * 100\n",
    "    print(\"%s: %s%%\" % (pred, RF_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11313203545422935 0.20966951113994864 0.5807263008248222\n"
     ]
    }
   ],
   "source": [
    "print(base_event_acc, LSTM_event_acc, RF_event_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6361256933360404 0.39611450599707637 0.40746741925040647\n"
     ]
    }
   ],
   "source": [
    "print(base_time_mae, LSTM_time_mae, RF_time_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20204502\\AppData\\Local\\Temp\\ipykernel_21512\\2233678611.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Time to next event'] = pd.to_datetime(test_df['Complete Timestamp']) + pd.to_timedelta(test_df['Time to next event'], unit='s')\n"
     ]
    }
   ],
   "source": [
    "test_df['Time to next event'] = pd.to_datetime(test_df['Complete Timestamp']) + pd.to_timedelta(test_df['Time to next event'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20204502\\AppData\\Local\\Temp\\ipykernel_21512\\2596003377.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Time prediction'] = pd.to_datetime(test_df['Complete Timestamp']) + pd.to_timedelta(test_df['Time prediction'])\n",
      "C:\\Users\\20204502\\AppData\\Local\\Temp\\ipykernel_21512\\2596003377.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['LSTM time prediction'] = pd.to_datetime(test_df['Complete Timestamp']) + pd.to_timedelta(test_df['LSTM time prediction'])\n",
      "C:\\Users\\20204502\\AppData\\Local\\Temp\\ipykernel_21512\\2596003377.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['RF time prediction'] = pd.to_datetime(test_df['Complete Timestamp']) + pd.to_timedelta(test_df['RF time prediction'])\n"
     ]
    }
   ],
   "source": [
    "test_df['Time prediction'] = pd.to_datetime(test_df['Complete Timestamp']) + pd.to_timedelta(test_df['Time prediction'], unit='ms')\n",
    "test_df['LSTM time prediction'] = pd.to_datetime(test_df['Complete Timestamp']) + pd.to_timedelta(test_df['LSTM time prediction'], unit='ms')\n",
    "test_df['RF time prediction'] = pd.to_datetime(test_df['Complete Timestamp']) + pd.to_timedelta(test_df['RF time prediction'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('output_log.csv', axis=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fafe8da2469ce22b82e1babda22c546ed40097b8f4cbd3e26d6446f22e5d370"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
