{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert timestamp to datetime (preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(dataset):\n",
    "    \"\"\"Adds a new column to a dataset with the converted timestamp to datetime\"\"\"\n",
    "\n",
    "    date_list = []\n",
    "\n",
    "    for time in dataset['event time:timestamp']:\n",
    "        datex = time[:-4]\n",
    "        date = datetime.strptime(datex, '%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "        date_list.append(date)\n",
    "\n",
    "    dataset['time and date'] = date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual next event and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_actual_next(df_case):\n",
    "    \"\"\"Adds the actual next activity and time to next event to the final dataframe\"\"\"\n",
    "\n",
    "\n",
    "    # Create a list for all the actual next events for an case\n",
    "    event_lst = [event for event in df_case['event concept:name']] # Gets a list of all events for a specific trace\n",
    "    event_lst = event_lst[1:] # Erase the first activity from the list (thus the second activity becomes first in the list)\n",
    "    event_lst.append('-') # Append a '-' to the end of the list (the last activity does not have a next activity)\n",
    "    \n",
    "    # Create a list for time of the next event\n",
    "    nexttime_lst1 = [time for time in df_case['time and date']]\n",
    "    nexttime_lst = nexttime_lst1[1:]\n",
    "    nexttime_lst.append(nexttime_lst[-1])\n",
    "\n",
    "    # Create the time difference list\n",
    "    time_diff = []\n",
    "    for i in range(len(nexttime_lst)):\n",
    "        time_diff.append(nexttime_lst[i] - nexttime_lst1[i])\n",
    "\n",
    "    # Append columns to the case dataframe\n",
    "    df_case['Next event'] = event_lst\n",
    "    df_case['Time to next event'] = time_diff\n",
    "\n",
    "    trace_len = len(df_case)\n",
    "\n",
    "    return trace_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted next event and time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_time(df_case, count_dict, time_dict):\n",
    "    for index, row in df_case.iterrows():\n",
    "        \n",
    "        # Get the amount of times an action occured in a certain position {action : {position_1 : count_1, position_2: count_2}}\n",
    "        if row['event concept:name'] in count_dict:\n",
    "            if index in count_dict[row['event concept:name']]:\n",
    "                count_dict[row['event concept:name']][index] += 1\n",
    "            else:\n",
    "                count_dict[row['event concept:name']].update({index: 1})\n",
    "        else:\n",
    "            count_dict[row['event concept:name']] = {index: 1}\n",
    "        \n",
    "        # Summation of the times to next action per position (index) {position: {\"sum\": summation_of_time, \"count\": amount_of_times_occured (to calculate mean)}}\n",
    "        if index in time_dict:\n",
    "            time_dict[index]['sum'] += row['Time to next event']\n",
    "            time_dict[index]['count'] += 1\n",
    "        else:\n",
    "            time_dict[index] = {'sum': row['Time to next event'], 'count': 1}\n",
    "\n",
    "def get_position_rank(max_trace_len, count_dict):\n",
    "    pos_rank_dict = {}\n",
    "    for i in range(max_trace_len):\n",
    "        init = 0\n",
    "        task = 0\n",
    "        for key in count_dict.keys():\n",
    "            try:\n",
    "                new = count_dict[key][i]\n",
    "            except:\n",
    "                new = 0\n",
    "            if new > init:\n",
    "                init = new\n",
    "                task = key\n",
    "\n",
    "        pos_rank_dict.update({i: task})\n",
    "    \n",
    "    return pos_rank_dict\n",
    "\n",
    "def get_mean_time(total_time_dict):\n",
    "    mean_time_dict = {}\n",
    "    for position in total_time_dict.keys():\n",
    "        mean_time = total_time_dict[position]['sum'] / total_time_dict[position]['count']\n",
    "        mean_time_dict[position] = mean_time\n",
    "    \n",
    "    return mean_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_pred(df_case, pos_rank_dict, mean_time_dict):\n",
    "    \n",
    "    # Prediction for the action\n",
    "    pred_act_lst = [pos_rank_dict[i] for i in range(len(df_case))]\n",
    "    pred_act_lst = pred_act_lst[1:]\n",
    "    pred_act_lst.append('-')\n",
    "\n",
    "    # Prediction for time\n",
    "    pred_time_lst = [mean_time_dict[i] for i in range(len(df_case))]\n",
    "\n",
    "    df_case['Event prediction'] = pred_act_lst \n",
    "    df_case['Time prediction'] = pred_time_lst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path, maximum=None):\n",
    "    \"\"\"Returns the training dataset with predictions and 2 dictionaries which predict next action and nexttime based on position\"\"\"\n",
    "    \n",
    "    dataset = pd.read_csv(path)\n",
    "    convert_time(dataset)\n",
    "\n",
    "    df_actual = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # Creating a dataframe with the actual events\n",
    "\n",
    "    cases = list(dataset['case concept:name'].unique())  \n",
    "    max_trace_len = 0  \n",
    "    pos_count_dict = {}\n",
    "    time_dict = {}\n",
    "    for case in cases[:maximum]:\n",
    "        df_case = dataset[dataset['case concept:name'] == case].copy().reset_index(drop=True)\n",
    "        trace_len = add_actual_next(df_case)\n",
    "        get_position_time(df_case, pos_count_dict, time_dict)\n",
    "        df_actual = df_actual.append(df_case)\n",
    "\n",
    "        if trace_len > max_trace_len:\n",
    "            max_trace_len = trace_len\n",
    "    \n",
    "\n",
    "\n",
    "    # Creating the predicitions\n",
    "    df_predicted = pd.DataFrame()\n",
    "    \n",
    "    pos_rank_dict = get_position_rank(max_trace_len, pos_count_dict)\n",
    "    mean_time_dict = get_mean_time(time_dict)\n",
    "\n",
    "    for case in cases[:maximum]:\n",
    "        df_case = df_actual[df_actual['case concept:name'] == case].copy().reset_index(drop=True)\n",
    "        create_event_pred(df_case, pos_rank_dict, mean_time_dict)\n",
    "        df_predicted = df_predicted.append(df_case)\n",
    "\n",
    "\n",
    "\n",
    "    return df_predicted, pos_rank_dict, mean_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(path, train_pos, train_time):\n",
    "    \"\"\"Creates the test dataset including the predictions based on the training dataset\"\"\"\n",
    "    \n",
    "    dataset = pd.read_csv(path)\n",
    "    convert_time(dataset)\n",
    "\n",
    "    df_predict = pd.DataFrame()\n",
    "    cases = list(dataset['case concept:name'].unique())  \n",
    "    for case in cases:\n",
    "        df_case = dataset[dataset['case concept:name'] == case].copy().reset_index(drop=True)\n",
    "        _ = add_actual_next(df_case)\n",
    "        create_event_pred(df_case, train_pos, train_time)\n",
    "        df_predict = df_predict.append(df_case)\n",
    "    \n",
    "    return df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(dataset):\n",
    "    correct_event = 0 \n",
    "    correct_time = 0\n",
    "    total = 0\n",
    "    for index, row in dataset.iterrows():\n",
    "        total += 1\n",
    "        if row['Next event'] == row['Event prediction']:\n",
    "            correct_event += 1\n",
    "        if row['Time to next event'] == row['Time prediction']:\n",
    "            correct_time += 1\n",
    "        \n",
    "    accuracy_event = correct_event/total \n",
    "    accuracy_time = correct_time/total\n",
    "\n",
    "    return accuracy_event, accuracy_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, train_pos, train_time = train('data\\BPI_Challenge_2012\\BPI_Challenge_2012-training.csv')\n",
    "df_test = test(\"data\\BPI_Challenge_2012\\BPI_Challenge_2012-test.csv\", train_pos, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'A_SUBMITTED',\n",
       " 1: 'A_PARTLYSUBMITTED',\n",
       " 2: 'W_Afhandelen leads',\n",
       " 3: 'W_Afhandelen leads',\n",
       " 4: 'W_Completeren aanvraag',\n",
       " 5: 'W_Completeren aanvraag',\n",
       " 6: 'W_Completeren aanvraag',\n",
       " 7: 'W_Completeren aanvraag',\n",
       " 8: 'W_Completeren aanvraag',\n",
       " 9: 'W_Completeren aanvraag',\n",
       " 10: 'W_Completeren aanvraag',\n",
       " 11: 'W_Completeren aanvraag',\n",
       " 12: 'W_Nabellen offertes',\n",
       " 13: 'W_Completeren aanvraag',\n",
       " 14: 'W_Nabellen offertes',\n",
       " 15: 'W_Nabellen offertes',\n",
       " 16: 'W_Nabellen offertes',\n",
       " 17: 'W_Nabellen offertes',\n",
       " 18: 'W_Nabellen offertes',\n",
       " 19: 'W_Nabellen offertes',\n",
       " 20: 'W_Nabellen offertes',\n",
       " 21: 'W_Nabellen offertes',\n",
       " 22: 'W_Nabellen offertes',\n",
       " 23: 'W_Nabellen offertes',\n",
       " 24: 'W_Nabellen offertes',\n",
       " 25: 'W_Nabellen offertes',\n",
       " 26: 'W_Nabellen offertes',\n",
       " 27: 'W_Nabellen offertes',\n",
       " 28: 'W_Nabellen offertes',\n",
       " 29: 'W_Nabellen offertes',\n",
       " 30: 'W_Nabellen offertes',\n",
       " 31: 'W_Nabellen offertes',\n",
       " 32: 'W_Nabellen offertes',\n",
       " 33: 'W_Nabellen offertes',\n",
       " 34: 'W_Nabellen offertes',\n",
       " 35: 'W_Nabellen offertes',\n",
       " 36: 'W_Nabellen offertes',\n",
       " 37: 'W_Nabellen offertes',\n",
       " 38: 'W_Nabellen incomplete dossiers',\n",
       " 39: 'W_Nabellen incomplete dossiers',\n",
       " 40: 'W_Nabellen incomplete dossiers',\n",
       " 41: 'W_Nabellen incomplete dossiers',\n",
       " 42: 'W_Nabellen incomplete dossiers',\n",
       " 43: 'W_Nabellen incomplete dossiers',\n",
       " 44: 'W_Nabellen incomplete dossiers',\n",
       " 45: 'W_Nabellen incomplete dossiers',\n",
       " 46: 'W_Nabellen incomplete dossiers',\n",
       " 47: 'W_Nabellen incomplete dossiers',\n",
       " 48: 'W_Nabellen incomplete dossiers',\n",
       " 49: 'W_Nabellen incomplete dossiers',\n",
       " 50: 'W_Nabellen incomplete dossiers',\n",
       " 51: 'W_Nabellen incomplete dossiers',\n",
       " 52: 'W_Nabellen incomplete dossiers',\n",
       " 53: 'W_Nabellen incomplete dossiers',\n",
       " 54: 'W_Nabellen incomplete dossiers',\n",
       " 55: 'W_Nabellen incomplete dossiers',\n",
       " 56: 'W_Nabellen incomplete dossiers',\n",
       " 57: 'W_Nabellen incomplete dossiers',\n",
       " 58: 'W_Nabellen incomplete dossiers',\n",
       " 59: 'W_Nabellen incomplete dossiers',\n",
       " 60: 'W_Nabellen incomplete dossiers',\n",
       " 61: 'W_Nabellen incomplete dossiers',\n",
       " 62: 'W_Nabellen incomplete dossiers',\n",
       " 63: 'W_Nabellen incomplete dossiers',\n",
       " 64: 'W_Nabellen incomplete dossiers',\n",
       " 65: 'W_Nabellen incomplete dossiers',\n",
       " 66: 'W_Nabellen incomplete dossiers',\n",
       " 67: 'W_Nabellen incomplete dossiers',\n",
       " 68: 'W_Nabellen incomplete dossiers',\n",
       " 69: 'W_Nabellen incomplete dossiers',\n",
       " 70: 'W_Nabellen incomplete dossiers',\n",
       " 71: 'W_Nabellen incomplete dossiers',\n",
       " 72: 'W_Nabellen incomplete dossiers',\n",
       " 73: 'W_Nabellen incomplete dossiers',\n",
       " 74: 'W_Nabellen incomplete dossiers',\n",
       " 75: 'W_Nabellen incomplete dossiers',\n",
       " 76: 'W_Nabellen incomplete dossiers',\n",
       " 77: 'W_Nabellen incomplete dossiers',\n",
       " 78: 'W_Nabellen incomplete dossiers',\n",
       " 79: 'W_Nabellen incomplete dossiers',\n",
       " 80: 'W_Nabellen incomplete dossiers',\n",
       " 81: 'W_Nabellen incomplete dossiers',\n",
       " 82: 'W_Nabellen incomplete dossiers',\n",
       " 83: 'W_Nabellen incomplete dossiers',\n",
       " 84: 'W_Nabellen incomplete dossiers',\n",
       " 85: 'W_Nabellen incomplete dossiers',\n",
       " 86: 'W_Nabellen incomplete dossiers',\n",
       " 87: 'W_Nabellen incomplete dossiers',\n",
       " 88: 'W_Nabellen incomplete dossiers',\n",
       " 89: 'W_Nabellen incomplete dossiers',\n",
       " 90: 'W_Nabellen incomplete dossiers',\n",
       " 91: 'W_Nabellen incomplete dossiers',\n",
       " 92: 'W_Nabellen incomplete dossiers',\n",
       " 93: 'W_Nabellen incomplete dossiers',\n",
       " 94: 'W_Nabellen incomplete dossiers',\n",
       " 95: 'W_Nabellen incomplete dossiers',\n",
       " 96: 'W_Nabellen incomplete dossiers',\n",
       " 97: 'W_Nabellen incomplete dossiers',\n",
       " 98: 'W_Nabellen incomplete dossiers',\n",
       " 99: 'W_Nabellen incomplete dossiers',\n",
       " 100: 'W_Nabellen incomplete dossiers',\n",
       " 101: 'W_Nabellen incomplete dossiers',\n",
       " 102: 'W_Nabellen incomplete dossiers',\n",
       " 103: 'W_Nabellen incomplete dossiers',\n",
       " 104: 'W_Nabellen incomplete dossiers',\n",
       " 105: 'W_Nabellen incomplete dossiers',\n",
       " 106: 'W_Nabellen incomplete dossiers',\n",
       " 107: 'W_Nabellen incomplete dossiers',\n",
       " 108: 'W_Nabellen incomplete dossiers',\n",
       " 109: 'W_Nabellen incomplete dossiers',\n",
       " 110: 'W_Nabellen incomplete dossiers',\n",
       " 111: 'W_Nabellen incomplete dossiers',\n",
       " 112: 'W_Nabellen incomplete dossiers',\n",
       " 113: 'W_Nabellen incomplete dossiers',\n",
       " 114: 'W_Nabellen incomplete dossiers',\n",
       " 115: 'W_Nabellen incomplete dossiers',\n",
       " 116: 'W_Nabellen incomplete dossiers',\n",
       " 117: 'W_Nabellen incomplete dossiers',\n",
       " 118: 'W_Nabellen incomplete dossiers',\n",
       " 119: 'W_Nabellen incomplete dossiers',\n",
       " 120: 'W_Nabellen incomplete dossiers',\n",
       " 121: 'W_Nabellen incomplete dossiers',\n",
       " 122: 'W_Nabellen incomplete dossiers',\n",
       " 123: 'W_Nabellen incomplete dossiers',\n",
       " 124: 'W_Nabellen incomplete dossiers',\n",
       " 125: 'W_Nabellen incomplete dossiers',\n",
       " 126: 'W_Nabellen incomplete dossiers',\n",
       " 127: 'W_Nabellen incomplete dossiers',\n",
       " 128: 'W_Nabellen incomplete dossiers',\n",
       " 129: 'W_Nabellen incomplete dossiers',\n",
       " 130: 'W_Nabellen incomplete dossiers',\n",
       " 131: 'W_Nabellen incomplete dossiers',\n",
       " 132: 'W_Nabellen incomplete dossiers',\n",
       " 133: 'W_Nabellen incomplete dossiers',\n",
       " 134: 'W_Nabellen incomplete dossiers',\n",
       " 135: 'W_Nabellen incomplete dossiers',\n",
       " 136: 'W_Nabellen incomplete dossiers',\n",
       " 137: 'W_Nabellen incomplete dossiers',\n",
       " 138: 'W_Nabellen incomplete dossiers',\n",
       " 139: 'W_Nabellen incomplete dossiers',\n",
       " 140: 'W_Nabellen incomplete dossiers',\n",
       " 141: 'W_Nabellen incomplete dossiers',\n",
       " 142: 'W_Nabellen incomplete dossiers',\n",
       " 143: 'W_Nabellen incomplete dossiers',\n",
       " 144: 'W_Nabellen incomplete dossiers',\n",
       " 145: 'W_Nabellen incomplete dossiers',\n",
       " 146: 'W_Nabellen incomplete dossiers',\n",
       " 147: 'W_Nabellen incomplete dossiers',\n",
       " 148: 'W_Nabellen incomplete dossiers',\n",
       " 149: 'W_Nabellen incomplete dossiers',\n",
       " 150: 'W_Nabellen incomplete dossiers',\n",
       " 151: 'W_Nabellen incomplete dossiers',\n",
       " 152: 'W_Nabellen incomplete dossiers',\n",
       " 153: 'W_Nabellen incomplete dossiers',\n",
       " 154: 'W_Nabellen incomplete dossiers',\n",
       " 155: 'W_Nabellen incomplete dossiers',\n",
       " 156: 'W_Nabellen incomplete dossiers',\n",
       " 157: 'W_Nabellen incomplete dossiers',\n",
       " 158: 'W_Nabellen incomplete dossiers',\n",
       " 159: 'W_Nabellen incomplete dossiers',\n",
       " 160: 'W_Nabellen incomplete dossiers',\n",
       " 161: 'W_Nabellen incomplete dossiers',\n",
       " 162: 'W_Nabellen incomplete dossiers',\n",
       " 163: 'W_Nabellen incomplete dossiers',\n",
       " 164: 'W_Nabellen incomplete dossiers',\n",
       " 165: 'W_Nabellen incomplete dossiers',\n",
       " 166: 'W_Nabellen incomplete dossiers',\n",
       " 167: 'A_CANCELLED',\n",
       " 168: 'O_CANCELLED',\n",
       " 169: 'W_Nabellen incomplete dossiers',\n",
       " 170: 'W_Nabellen incomplete dossiers',\n",
       " 171: 'W_Nabellen incomplete dossiers',\n",
       " 172: 'O_CANCELLED',\n",
       " 173: 'A_CANCELLED',\n",
       " 174: 'W_Nabellen incomplete dossiers'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_event_acc, train_time_acc = get_accuracy(df_train)\n",
    "test_event_acc, test_time_acc = get_accuracy(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48038269030726244, 2.332339756597023e-05)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_event_acc, train_time_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4816929092695983, 0.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_event_acc, test_time_acc"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84124d46dd126ec8d7ff94d5f94a4fab5c1e6d48237b4564158d565a05f31086"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
